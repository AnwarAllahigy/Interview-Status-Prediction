# -*- coding: utf-8 -*-
"""Interview_Status_Prediction_By_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xgwAt0L6EBOlwe8AZ3wC2jHWMG4OVu-t

#**Interview Status Prediction by Machine Learning**
---By **Anwar Hashem** (PhD Student)

## **Importing Libraries**
--- here we importing the needed **Libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np

from sklearn.feature_selection import SelectPercentile, chi2, f_classif
from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder

from sklearn.tree import DecisionTreeClassifier #Decision Tree
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier #Random Forest, AdaBoost, Gradient Boosting
from sklearn.metrics import confusion_matrix, classification_report


import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set(style="white", color_codes=True)

"""## **Reading Data**
---3 files about Interview Status Prediction downloaded as the following:

---1- Result: https://fastupload.io/b6d9f28a70ae2722

---2- Test: https://fastupload.io/d1408114e1a38d33

---3- Train: https://fastupload.io/6c39710a81864f69

"""

train_ds = pd.read_csv('/content/train.csv')
test_ds = pd.read_csv('/content/test-result.csv')

pd.set_option("display.max_columns", 70)
pd.set_option("display.max_rows", 200)

train_ds.columns

test_ds.columns

"""From above we found that train_ds, test_ds have the same structure expet
We find that  train_ds, test_ds have the same Features names, "Status" represins the output.
"""

train_ds.shape

test_ds.shape

"""From above we found that train_ds (79.3%), Test_ds(20.7%) from all dataset."""

train_ds.head()

test_ds.head()

"""#**EDA -Exploratory Data Analysis**"""

train_ds.info()

train_ds.describe()

test_ds.describe()

"""#ِ**Data preprocessing**

##**Handling missing values**

###**Missing Values in Training data**
"""

train_ds.isnull().sum()

"""### **Null values ​​in training data as the following:**
### A- Features (input data)
####- P.E.I (1 value), P.E.C (3 values), Interviewer Intro (1 value) and Opp to ask (1 value)

###B- Target (output data):
####- Status (4 values)

### ***Selecting Rows Whose Column Value is Null None Nan***
"""

null_mask = train_ds.isnull().any(axis=1)
null_rows = train_ds[null_mask]

print(null_rows)

"""The rows that have null values in output (Status) is (349, 3807, 3816, 5795)
We need to remove thin rows.
"""

#Remove the rows(349, 3807, 3816, 5795) that have null values in output (Status)
##train_ds.drop([349,3807,3816,5795],axis=0,inplace=True)
#train_ds.reset_index(inplace=True)
#train_ds.drop(['index','level_0'],axis=1,inplace=True)

"""For missing values ​​in the Features or training data , we can address them with appropriate statistics by filling them in as follows:
- Numerical Features ​​(can be filled with the Mean).
- Categorical Features ​​(can be filled with the Mode).

But since the missing records are very small and will not affect the integrity of the data, we can delete them.
"""

'''
for x in train_ds.columns:
    if train_ds[x].dtype=="object" or train_ds[x].dtype=="bool":
        train_ds[x].fillna(train_ds[x].mode()[0], inplace=True)
    elif train_ds[x].dtype=="int64" or train_ds[x].dtype=="float64":
        train_ds[x].fillna(round(train_ds[x].mean()), inplace=True)
train_ds.isnull().sum()
'''

#Remove the rows(16,50,349,361, 1993, 3807,3811, 3816,3818,5795) that have null values
##train_ds.drop([3809],axis=0,inplace=True)
train_ds.drop([16,50,349,361, 1993, 3807,3811, 3816,3818,5795],axis=0,inplace=True)
train_ds.reset_index(inplace=True)
train_ds.drop(['index'],axis=1,inplace=True)

#Remove the rows(360) that have null values in the columun (Interviewer Intro)
#train_ds.drop([360],axis=0,inplace=True)

#Remove the rows(16,50,1992) that have null values in the columun (P.E.C)
#train_ds.drop([16,50,1992],axis=0,inplace=True)

#Remove the rows(3814) that have null values in the columun (P.E.I)
#train_ds.drop([3814],axis=0,inplace=True)

train_ds.info()

train_ds.to_csv("train_after_preprocessing.csv")

"""##**Duplicated Data**"""

#train_ds.duplicated().sum()
train_ds['Interview Id'].duplicated().sum()
#There are No dupicates in the training data

test_ds.duplicated().sum()
#There are No dupicates in the test data

"""###**Missing Values in Test data**"""

test_ds.info()

test_ds.isnull().sum()

"""## **Null values ​​in test data:**
### A- Features (input data)
####- S.L.R.I (1 value), L.J.T.C (1 values), S.P.I  (2 values), L.A.I (1 value), Q.A (1 value), P.E.I (2 values), P.E.C (2 values), COMPLIANCE Ratio (1 value) and Interviewer Intro (2 values)

###B- Target (output data):
####- Status (?? values)

### ***Selecting Rows Whose Column Value is Null None Nan***
"""

null_mask = test_ds.isnull().any(axis=1)
null_rows = test_ds[null_mask]

print(null_rows)

"""The rows that have null values in Features of test data is (8,55,56,61,152,157,215,247,268,305,318,460,524)
We may remove thin rows.

For missing values ​​in the Features of test data , we can address them with appropriate statistics by filling them in as follows:
- Numerical Features ​​(can be filled with the Mean).
- Categorical Features ​​(can be filled with the Mode).

But since the missing records are very small and will not affect the integrity of the data, we can delete them.
"""

'''
for x in test_ds.columns:
    if test_ds[x].dtype=="object" or test_ds[x].dtype=="bool":
        test_ds[x].fillna(test_ds[x].mode()[0], inplace=True)
    elif test_ds[x].dtype=="int64" or test_ds[x].dtype=="float64":
        test_ds[x].fillna(round(test_ds[x].mean()), inplace=True)
test_ds.isnull().sum()
'''

#Remove the rows(8,55,56,61,152,157,215,247,268,305,318,460,524) that have null values in Features of test data
test_ds.drop([8,55,56,61,152,157,215,247,268,305,318,460,524],axis=0,inplace=True)
test_ds.reset_index(inplace=True)
test_ds.drop(['index'],axis=1,inplace=True)

test_ds.info()

test_ds.to_csv("test_after_preprocessing.csv")

"""##**Histogram**
###**Check Data Distribution**
"""

category_cols = train_ds.dtypes[train_ds.dtypes=='object'].index
numuric_cols = train_ds.dtypes[train_ds.dtypes!='object'].index
print('Category Cloumuns:\n', category_cols)
print('Numerical Cloumuns:\n', numuric_cols)

##import seaborn as sns
##import matplotlib.pyplot as plt

# Assuming 'stud' is your Pandas DataFrame containing your data
# Replace 'stud' with your actual DataFrame

# Get the list of column names
##columns = stud.columns
columns=category_cols

# Set the number of bins for the histograms
num_bins = 20  # You can adjust this as needed

# Loop through each column and create a histogram
for column in columns:
    plt.figure(figsize=(20, 4))  # Adjust the figure size as needed
    sns.histplot(data=train_ds, x=column, bins=num_bins)
    plt.title(f'Distribution of {column}')
    plt.xlabel(f'{column} Values')
    plt.ylabel('Frequency')
    plt.show()
''''
for i in category_cols:
    sns.countplot(y=train_ds[i])
    plt.title(f'Countplot for {i}')
    plt.show()
'''

"""##**Boxplot**
###**Outlier Handling**
"""

for i in numuric_cols:
    sns.boxplot(y=train_ds[i])
    plt.title(f'Boxplot for {i}')
    plt.show()

train_ds.describe()

train_ds.describe(percentiles=[0.01,0.02,0.03,0.05,0.95,0.96,0.97,0.98,0.99]).T

"""We found that Interview duration:
-	Mean: 37.3 minutes
-	Standard deviation: 13.2 minutes.
-	Shortest interview: 15 minutes
-	Longest Interview: 60 minutes

### **Calculating  the Outlier**
"""

for x in ['S.L.R.C', 'S.L.R.I','A.T.T', 'L.M.I', 'L.M.C', 'S.R', 'L.J.T.C', 'L.J.T.I', 'N.I.C','N.I.I', 'S.P.I', 'S.P.C', 'L.A.C', 'L.A.I', 'Q.A', 'COMPLIANCE Ratio','Interview duration']:
#for x in ['L.M.I']:
  q75,q25 = np.percentile(train_ds.loc[:,x],[75,25])
  intr_qr=q75-q25
  max=q75+(1.5*intr_qr)
  min=q25-(1.5*intr_qr)
  print(f'For {x} Min outliers has {train_ds.loc[train_ds[x] < min,x].shape[0]} rows amd Max has {train_ds.loc[train_ds[x] > max,x].shape[0]} rows')

"""###**So, We found fronm above that there is no outliers**

##**Encoding**
"""

train_ds.head()

category_cols = train_ds.dtypes[train_ds.dtypes=='object'].index
print('Category Cloumuns:\n', category_cols)

#train_ds_encoded = pd.get_dummies(train_ds, columns=['Profile'])
train_ds_encoded=train_ds.copy()
test_ds_encoded=test_ds.copy()
train_ds_encoded.shape

'''
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for x in Category Cols:
    train_ds_encoded[x]=le.fit_transform(train_ds_encoded[x])
    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
    print('Feature', x)
    print('mapping', le_name_mapping)
'''

# Encoding feature 'Profile'
train_ds_encoded['Profile'].value_counts()

train_ds_encoded['Profile'] = train_ds_encoded['Profile'].replace('Developer', 1) #ok
train_ds_encoded['Profile'] = train_ds_encoded['Profile'].replace('Account Manager', 2)
train_ds_encoded['Profile'] = train_ds_encoded['Profile'].replace('Sales', 3) # not ok
train_ds_encoded['Profile'] = train_ds_encoded['Profile'].replace('QA Manual', 4) #ok
train_ds_encoded['Profile'] = train_ds_encoded['Profile'].replace('QA Automation', 5) #ok
train_ds_encoded['Profile'] = train_ds_encoded['Profile'].replace('Marketing', 6)
train_ds_encoded['Profile'] = train_ds_encoded['Profile'].replace('Product Manager', 7)
train_ds_encoded['Profile'] = train_ds_encoded['Profile'].replace('Program Manager', 8)
train_ds_encoded['Profile'] = train_ds_encoded['Profile'].replace('Data Scientist', 9)
train_ds_encoded['Profile'] = train_ds_encoded['Profile'].replace('HR', 10)

train_ds_encoded['Profile'].value_counts()

test_ds_encoded['Profile'].value_counts()

test_ds_encoded['Profile'] = test_ds_encoded['Profile'].replace('Developer', 1)
test_ds_encoded['Profile'] = test_ds_encoded['Profile'].replace('Account Manager', 2)
test_ds_encoded['Profile'] = test_ds_encoded['Profile'].replace('Sales', 3)
test_ds_encoded['Profile'] = test_ds_encoded['Profile'].replace('QA Manual', 4)
test_ds_encoded['Profile'] = test_ds_encoded['Profile'].replace('QA Automation', 5)
test_ds_encoded['Profile'] = test_ds_encoded['Profile'].replace('Marketing', 6)
test_ds_encoded['Profile'] = test_ds_encoded['Profile'].replace('Product Manager', 7)
test_ds_encoded['Profile'] = test_ds_encoded['Profile'].replace('Program Manager', 8)
test_ds_encoded['Profile'] = test_ds_encoded['Profile'].replace('Data Scientist', 9)
test_ds_encoded['Profile'] = test_ds_encoded['Profile'].replace('HR', 10)

test_ds_encoded['Profile'].value_counts()

# Encoding feature P.E.I
train_ds_encoded['P.E.I'].value_counts()

train_ds_encoded['P.E.I'] = train_ds_encoded['P.E.I'].replace('Negative', 0)
train_ds_encoded['P.E.I'] = train_ds_encoded['P.E.I'].replace('Neutral', 1)
train_ds_encoded['P.E.I'] = train_ds_encoded['P.E.I'].replace('Positive', 2)

train_ds_encoded['P.E.I'].value_counts()

test_ds_encoded['P.E.I'].value_counts()

test_ds_encoded['P.E.I'] = test_ds_encoded['P.E.I'].replace('Negative', 0)
test_ds_encoded['P.E.I'] = test_ds_encoded['P.E.I'].replace('Neutral', 1)
test_ds_encoded['P.E.I'] = test_ds_encoded['P.E.I'].replace('Positive', 2)

test_ds_encoded['P.E.I'].value_counts()

# Encoding Feature 'P.E.C'
train_ds_encoded['P.E.C'].value_counts()

train_ds_encoded['P.E.C'] = train_ds_encoded['P.E.C'].replace('Negative', 0)
train_ds_encoded['P.E.C'] = train_ds_encoded['P.E.C'].replace('Neutral', 1)
train_ds_encoded['P.E.C'] = train_ds_encoded['P.E.C'].replace('Positive', 2)

train_ds_encoded['P.E.C'].value_counts()

test_ds_encoded['P.E.C'].value_counts()

test_ds_encoded['P.E.C'] = test_ds_encoded['P.E.C'].replace('Negative', 0)
test_ds_encoded['P.E.C'] = test_ds_encoded['P.E.C'].replace('Neutral', 1)
test_ds_encoded['P.E.C'] = test_ds_encoded['P.E.C'].replace('Positive', 2)

test_ds_encoded['P.E.C'].value_counts()

# Encoding Feature 'Interviewer Intro'
train_ds_encoded['Interviewer Intro'].value_counts()

train_ds_encoded['Interviewer Intro'] = train_ds_encoded['Interviewer Intro'].replace('No', 0)
train_ds_encoded['Interviewer Intro'] = train_ds_encoded['Interviewer Intro'].replace('Yes', 1)

train_ds_encoded['Interviewer Intro'].value_counts()

test_ds_encoded['Interviewer Intro'].value_counts()

test_ds_encoded['Interviewer Intro'] = test_ds_encoded['Interviewer Intro'].replace('No', 0)
test_ds_encoded['Interviewer Intro'] = test_ds_encoded['Interviewer Intro'].replace('Yes', 1)

test_ds_encoded['Interviewer Intro'].value_counts()

# Encoding Feature 'Candidate into'
train_ds_encoded['Candidate into'].value_counts()

train_ds_encoded['Candidate into'] = train_ds_encoded['Candidate into'].replace('No', 0)
train_ds_encoded['Candidate into'] = train_ds_encoded['Candidate into'].replace('Yes', 1)

train_ds_encoded['Candidate into'].value_counts()

test_ds_encoded['Candidate into'].value_counts()

test_ds_encoded['Candidate into'] = test_ds_encoded['Candidate into'].replace('No', 0)
test_ds_encoded['Candidate into'] = test_ds_encoded['Candidate into'].replace('Yes', 1)

test_ds_encoded['Candidate into'].value_counts()

# Encoding Feature 'Opp to ask'
train_ds_encoded['Opp to ask'].value_counts()

train_ds_encoded['Opp to ask'] = train_ds_encoded['Opp to ask'].replace('No', 0)
train_ds_encoded['Opp to ask'] = train_ds_encoded['Opp to ask'].replace('Yes', 1)

train_ds_encoded['Opp to ask'].value_counts()

test_ds_encoded['Opp to ask'].value_counts()

test_ds_encoded['Opp to ask'] = test_ds_encoded['Opp to ask'].replace('No', 0)
test_ds_encoded['Opp to ask'] = test_ds_encoded['Opp to ask'].replace('Yes', 1)

test_ds_encoded['Opp to ask'].value_counts()

# Encoding Feature 'Status'
train_ds_encoded['Status'].value_counts()

train_ds_encoded['Status'] = train_ds_encoded['Status'].replace('Not Consider', 0)
train_ds_encoded['Status'] = train_ds_encoded['Status'].replace('May Consider', 1)
train_ds_encoded['Status'] = train_ds_encoded['Status'].replace('Consider', 2)

train_ds_encoded['Status'].value_counts()

test_ds_encoded['Status'].value_counts()

test_ds_encoded['Status'] = test_ds_encoded['Status'].replace('Not Consider', 0)
test_ds_encoded['Status'] = test_ds_encoded['Status'].replace('May Consider', 1)
test_ds_encoded['Status'] = test_ds_encoded['Status'].replace('Consider', 2)

test_ds_encoded['Status'].value_counts()

"""### **The Correlations**
Check the Correlation between the variables.
"""

train_ds_encoded.info()

#draw heatmap
#import seaborn as sns
#get correlations of each features in dataset
corrmat = train_ds_encoded.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(40,40))
#plot heat map
g=sns.heatmap(train_ds_encoded[top_corr_features].corr(),annot=True,cmap="RdYlGn")

'''
corr = train_ds[numuric_cols].corr()
plt.figure(figsize=(20,10))
sns.heatmap(corr,annot=True)
plt.show()
'''

'''
plt.figure(figsize=(20,10))
sns.heatmap(corr[abs(corr)>=0.7],annot=True)
plt.show()
'''

"""From above we found that the highly correlated features is:
S.L.R.C, S.L.R.I

##**Features Selection**
"""

# Also We can remove the columuns 'Interview Id','Candidate Id','Interviewer Id'because no effect of them.
train_ds_encoded.drop(['Interview Id','Candidate Id','Interviewer Id'],axis=1,inplace=True)
#train_ds

test_ds_encoded.drop(['Interview Id','Candidate Id','Interviewer Id'],axis=1,inplace=True)
#test_ds

x_tr= train_ds_encoded.drop(['Status'],axis=1)
y_tr = train_ds_encoded['Status']

x_te= train_ds_encoded.drop(['Status'],axis=1)
y_te = train_ds_encoded['Status']
print('x_train shape is ' , x_tr.shape)
print('y_train shape is ' , y_tr.shape)
print('x_test shape is ' , x_te.shape)
print('y_test shape is ' , y_te.shape)
#corr = train_ds[numuric_cols].corr()
corr = train_ds_encoded.corr()['Status']
corr

# An other method for features Selection
featureSelection=SelectPercentile(score_func=chi2,percentile=20) #score_func=chi2(for positive values) ,or f_classif for othere

X_selected=featureSelection.fit_transform(x_tr,y_tr)
#X_selected
#x_tr.columns
#featureSelection.get_support()
pd.DataFrame(X_selected,columns=[i for i,j in zip(x_tr.columns,featureSelection.get_support())  if j==True])

"""##Result of Feature Selection
From above we found that the more important Features is:
'L.M.C', 'L.J.T.C', 'N.I.C', 'S.P.C', 'Interview duration
The importance order of features as the following:

1- L.J.T.C              -0.856376

2- S.P.C                 0.203198

3- L.M.C                 0.194775

4- N.I.C                -0.155696

5- Interview duration    0.114197


so, we can remove other features to get the Best Accuracy.
"""

##import matplotlib.pyplot as plt
##import seaborn as sns

# Assuming 'stud' is your DataFrame and you've already calculated the correlation matrix
# Calculate the correlation matrix
'''
corr_matrix = train_ds_encoded.corr()

# set up the matplotlib figure
f, ax = plt.subplots(figsize=(18, 18))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(220, 10, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
heatmap = sns.heatmap(corr , cmap=cmap, center=0.0, vmax=1, linewidths=1, ax=ax)
plt.show()
'''

train_ds_encoded.to_csv("train_after_encoding.csv")
test_ds_encoded.to_csv("test_after_encoding.csv")

train_ds =train_ds_encoded
test_ds = test_ds_encoded

"""## **Preparing inputs and outputs data:**"""

x_tr= train_ds.drop(['Status'],axis=1)
y_tr = train_ds['Status']

x_te= test_ds.drop(['Status'],axis=1)
y_te = test_ds['Status']
print('x_train shape is ' , x_tr.shape)
print('y_train shape is ' , y_tr.shape)
print('x_test shape is ' , x_te.shape)
print('y_test shape is ' , y_te.shape)

"""###**Scatter Plot**"""

sns.FacetGrid(train_ds,hue="Status",height=10).map(plt.scatter,"L.J.T.C","S.P.C").add_legeng()

#data_r = sns.load_dataset(data_r_path)
plt.figure(figsize=(10,10))
#sns.set_style("darkgrid")
sns.scatterplot(x='L.J.T.C' , y='S.P.C', data=train_ds,hue='Status')
plt.title("L.J.T.C vs. S.P.C")
plt.xlabel('L.J.T.C')
plt.show()

def eval_model(model,x_train,y_train,x_test,y_test,model_name):
    model.fit(x_train,y_train)
    ypred = model.predict(x_test)
    train_accuracy = model.score(x_train,y_train)
    test_accuracy = model.score(x_test,y_test)
    cm = confusion_matrix(y_test,ypred)
    cr = classification_report(y_test,ypred)
    res_df = pd.DataFrame({'Train_Accuracy':train_accuracy,'Test_Accuracy':test_accuracy},index=[model_name])
    print('Confusion_Matrix\n',cm)
    print('Classification Report\n',cr)
    return res_df

"""### Decision Tree Classifier"""

DecisionTree= DecisionTreeClassifier(criterion='gini',max_depth=12,min_samples_split=15)
DecisionTree_res = eval_model(DecisionTree,x_tr,y_tr,x_te,y_te,'Decision Tree')
DecisionTree_res

"""### Random Forest Classifier"""

RandomForest = RandomForestClassifier(n_estimators=80,criterion='gini',max_depth=12,min_samples_split=15)
RandomForest_res = eval_model(RandomForest,x_tr,y_tr,x_te,y_te,'Random Forest')
RandomForest_res

"""### Adaboost Classifier"""

AdaBoost = AdaBoostClassifier(n_estimators=1000)  # depth of tree = 1
AdaBoost_res = eval_model(AdaBoost,x_tr,y_tr,x_te,y_te,'AdaBoost')
AdaBoost_res

"""### Gradient Boosting"""

GradientBoosting = GradientBoostingClassifier(n_estimators=200,learning_rate=0.05,random_state=8,max_features=15)
GradientBoosting_res = eval_model(GradientBoosting,x_tr,y_tr,x_te,y_te,'Gradient Boosting')
GradientBoosting_res

Models_res = pd.concat([DecisionTree_res,RandomForest_res,AdaBoost_res,GradientBoosting_res])
Models_res

"""### According to the results: Adaboost Algorithms is the best performance for new data, then Gradient Boosting, then Random Forest, and finally Decision Tree."""